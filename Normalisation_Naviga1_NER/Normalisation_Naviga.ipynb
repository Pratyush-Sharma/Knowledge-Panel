{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules and Creating Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "- DATA USED - Naviga_Entity_Extraction_v002.xlsx\n",
    "\n",
    "\n",
    "- FILES CREATED - locations_norm2raw_v036, locations_raw2norm_v036, organizations_norm2raw_v036, organizations_raw2norm_v036, persons_norm2raw_v036, persons_raw2norm_v036\n",
    "               \n",
    "\n",
    "- Matching algorithms of notebook 'entity_normalization_ver_0_3_6' were combined in a script file Normalization_Helper.py and used, Co Document Ratio was not used\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from itertools import combinations\n",
    "import unicodedata\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia as wiki\n",
    "import Levenshtein as lvst\n",
    "from metaphone import doublemetaphone as dmt_phone\n",
    "import networkx as nx\n",
    "import nxviz as nv\n",
    "from sparse_dot_topn import awesome_cossim_topn as cossim_topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.symbols import nsubj, VERB, NOUN\n",
    "from spacy.tokens import Doc, Token, Span\n",
    "from spacy.attrs import ENT_IOB, ENT_TYPE\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"Naviga_Entity_Extraction_v002.xlsx\")\n",
    "df = df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons= df[\"Person_Naviga\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = df[\"Company_Naviga\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = df[\"Location_Naviga\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Kobe Bryant\n",
       "1              LeBron James\n",
       "2            Michael Jordan\n",
       "3               Bill Russel\n",
       "4              Robert Horry\n",
       "                ...        \n",
       "27836          Seth Goodman\n",
       "27837            Gary Davis\n",
       "27838            Doug Finke\n",
       "27839         Zoya Akhtar's\n",
       "27840    Arundhuti Banerjee\n",
       "Name: Person_Naviga, Length: 27841, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "In this section, I explore several approaches to normalize entity names. Experiments is being done for *Person names*.\n",
    "\n",
    "- **Matching Algorithms** (Ensemble or Hierarchical)\n",
    "    - String simiarity: Levenshtein distance, Jaro-Winkler distance\n",
    "    - Normalizing to ASCII (for non-english character-encoded names)\n",
    "    - Removing special characters and white spaces\n",
    "    - Doublemetaphone matching\n",
    "    - Word sorting by first letters of chunk (for example, William Telle &rarr; Telle William)\n",
    "    - Subword-level TF-IDF expansion and consine-simliarity\n",
    "    - Abbreviation/Acronym matching by Wikipedia data investigation and linking\n",
    "    - Expanding to normal words (e.g. Stephen W. Hawking &rarr; Stephen Willam Hawking) - need to investigate HOW to\n",
    "\n",
    "- **Use ensemble method**\n",
    "    - Apply different weight schemes for different entity-types\n",
    "\n",
    "- **Find normalzed form of names**\n",
    "    - detect connected components\n",
    "    - use distance-median, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lieutenant Colonel', 'treasury secretary', 'lieutenant general', 'Treasury Secretary', 'Lieutenant General', 'lieutenant colonel', 'defense secratery', 'Defence Secratery', 'Defense Secratery', 'defence secratery', 'defence minister', 'Defence Minister', 'defense minister', 'Defense Minister', 'deputy director', 'Party Secretary', 'party secretary', 'General Manager', 'Deputy Director', 'general manager', 'vice president', 'Prime Minister', 'Vice President', 'prime minister', 'major general', 'Management MG', 'Major General', 'management mg', 'ambassador', 'Major Gen.', 'lieutenant', 'management', 'Ambassador', 'Management', 'Lieutenant', 'major gen.', 'Secratery', 'Secretary', 'army gen.', 'secretary', 'Army Gen.', 'president', 'President', 'Major Gen', 'major gen', 'secratery', 'army gen', 'Marshall', 'Army Gen', 'Treasury', 'Minister', 'director', 'treasury', 'minister', 'marshall', 'Director', 'Colonel', 'Defence', 'general', 'General', 'Manager', 'Speaker', 'Premier', 'Admiral', 'premier', 'defence', 'manager', 'defense', 'admiral', 'colonel', 'speaker', 'Defense', 'deputy', 'Deputy', 'maddam', 'Maddam', 'major', 'Party', \"Ma'am\", \"ma'am\", 'party', 'prime', 'Major', 'Prime', 'Vice', 'Army', 'army', 'miss', 'gen.', 'Sir.', 'vice', 'Gen.', 'Miss', 'Mrs.', 'sir.', 'mrs.', 'Dr.', 'ltg', 'Sir', 'gen', 'Mr.', 'mrs', 'dr.', 'sir', 'LTG', 'Gen', 'ms.', 'Mrs', 'Ms.', 'mr.', 'Dr', 'mg', 'ms', 'Mr', 'dr', 'Ms', 'mr', 'MG']\n"
     ]
    }
   ],
   "source": [
    "prefixes1 = ['Mr.', 'Mrs.', 'Ms.', 'Miss', 'Dr.', 'Sir', 'Sir.', \"Ma'am\", 'Maddam']\n",
    "prefixes2 = ['President', 'Gen.', 'Prime Minister', 'Director', 'Deputy Director', 'Army Gen.'\n",
    "            , 'General',  'Secretary', 'Treasury Secretary', 'Major General', 'Major Gen.'\n",
    "            , 'Colonel', 'Lieutenant Colonel', 'LTG', 'Minister', 'Ambassador', 'Premier'\n",
    "            , 'Management MG', 'MG', 'Lieutenant General', 'Defence Minister', 'Admiral'\n",
    "            , 'General Manager', 'Party Secretary', 'Speaker', 'Defense Minister'\n",
    "            , 'Defence Secratery', 'Defense Secratery', 'Marshall', 'Vice President'\n",
    "            ]\n",
    "prefixes1_lower = [p.lower() for p in prefixes1]\n",
    "prefixes2_lower = [p.lower() for p in prefixes2]\n",
    "\n",
    "prefixes_all = prefixes1 + prefixes2 + prefixes1_lower + prefixes2_lower\n",
    "\n",
    "for pf in prefixes_all:\n",
    "    if pf[-1] == '.':\n",
    "        prefixes_all.append(pf[:-1])\n",
    "        \n",
    "for pf in prefixes_all:\n",
    "    if len(pf.split()) > 1:\n",
    "        prefixes_all.extend(pf.split())\n",
    "\n",
    "prefixes_all = list(set(prefixes_all))\n",
    "prefixes_all.sort(key=len, reverse=True)\n",
    "\n",
    "               \n",
    "print(prefixes_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(data, n=3, captialized_1st=True, prefix2remove=prefixes_all):\n",
    "    '''\n",
    "    generate subword-level ngrams\n",
    "    '''\n",
    "    # dealing non-ASCII characters\n",
    "    normal = unicodedata.normalize('NFKD', data).encode('ASCII', 'ignore')\n",
    "    val = normal.decode(\"utf-8\") # no lovercasing yet\n",
    "    \n",
    "    # remove prefix\n",
    "    if prefix2remove:  \n",
    "        for prefix in prefix2remove:\n",
    "            val = val.replace(prefix, '')\n",
    "            #val = val[1:] if val[0] == ' ' else val # remove any starting white space\n",
    "    \n",
    "    # lowercasing\n",
    "    val = val.lower()\n",
    "    # remove special characters\n",
    "    val = re.sub('[^A-Za-z0-9 ]+', ' ', val)\n",
    "    # remove multiple spaces\n",
    "    val = re.sub(' +', ' ', val)\n",
    "    \n",
    "    #print(val)\n",
    "    \n",
    "    # Capitalized 1st letter of every word\n",
    "    if captialized_1st: \n",
    "        val = val.title()\n",
    "    # padding\n",
    "    padding = ' '\n",
    "    val = padding + val + padding\n",
    "    #string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    \n",
    "    ngrams = zip(*[val[i:] for i in range(n)])\n",
    "    \n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=generate_ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27841, 10132)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cossim_topn(tf_idf_matrix, tf_idf_matrix.transpose(), 2, 0.01, use_threads=True, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(similarity_matrix, A, B):\n",
    "        '''\n",
    "        Takes a matrix with similarity scores and two arrays, A and B,\n",
    "        as an input and returns the matches with the score as a dataframe.\n",
    "        Args:\n",
    "            similarity_matrix (csr_matrix)  : The matrix (dimensions: len(A)*len(B)) with the similarity scores\n",
    "            A              (pandas.Series)  : The array to be matched (dirty)\n",
    "            B              (pandas.Series)  : The baseline array (clean)\n",
    "        Returns:\n",
    "            pandas.Dataframe : Array with matches between A and B plus scores\n",
    "        '''\n",
    "        non_zeros = similarity_matrix.nonzero()\n",
    "\n",
    "        sparserows = non_zeros[0]\n",
    "        sparsecols = non_zeros[1]\n",
    "\n",
    "        nr_matches = sparsecols.size\n",
    "\n",
    "        in_text = np.empty([nr_matches], dtype=object)\n",
    "        matched = np.empty([nr_matches], dtype=object)\n",
    "        similarity = np.zeros(nr_matches)\n",
    "\n",
    "        in_text = np.array(A)[sparserows]\n",
    "        matched = np.array(B)[sparsecols]\n",
    "        similarity = np.array(similarity_matrix.data)\n",
    "\n",
    "        df_tuples = list(zip(in_text, matched, similarity))\n",
    "\n",
    "        return pd.DataFrame(df_tuples, columns=['in_text', 'matched', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicated_match(df, col1='in_text', col2='matched'):\n",
    "    '''\n",
    "    generate a temporary column of \"pair\" and use it for de-duping and remove it\n",
    "    '''\n",
    "    temp = list()\n",
    "    names1 = df[col1].tolist()\n",
    "    names2 = df[col2].tolist()\n",
    "    for tp in zip(names1, names2):\n",
    "        temp.append(str(sorted(list(tp))))\n",
    "    \n",
    "    df['pair'] = temp\n",
    "    df.drop_duplicates(subset=\"pair\", inplace=True)\n",
    "    df.drop(columns=['pair'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simliar_names_by_tfdif(names, topN=2, threshold=0.7, remove_selfMatch=True, verbose=0):\n",
    "    '''\n",
    "    To Do: function description\n",
    "    '''\n",
    "    # get subword-level tf-idf features for each names\n",
    "    vectorizer = TfidfVectorizer(min_df=1, analyzer=generate_ngrams)\n",
    "    tf_idf_mat = vectorizer.fit_transform(names)\n",
    "    if verbose:\n",
    "        print('tf_idf_mat size: {}'.format(tf_idf_mat.shape))\n",
    "    \n",
    "    # get top N simliar names by consine simliarity\n",
    "    similarity_mat = cossim_topn(tf_idf_mat, tf_idf_mat.transpose(),\n",
    "                                 topN, use_threads=True, n_jobs=4)\n",
    "    \n",
    "    # get dataframe of matched result\n",
    "    df_matched = get_matches_df(similarity_mat, pd.Series(names), pd.Series(names))\n",
    "    if verbose:\n",
    "        print('df_matched_raw size: {}'.format(df_matched.shape))\n",
    "    \n",
    "    # filter by simliarity threshold and remove self-matching\n",
    "    df_matched = df_matched[(df_matched.similarity > threshold)]\n",
    "    \n",
    "    # remove self-matching:\n",
    "    if remove_selfMatch:\n",
    "        df_matched = df_matched[(df_matched.in_text != df_matched.matched)]\n",
    "    \n",
    "    # retain only one copy of matched pairs\n",
    "    #df_matched.drop_duplicates(subset=\"similarity\", inplace=True)\n",
    "    df_matched = remove_duplicated_match(df_matched)\n",
    "    \n",
    "    # reverse sort by simliarty\n",
    "    df_matched.sort_values(by=['similarity'], ascending=False, inplace=True)\n",
    "    \n",
    "    if verbose:\n",
    "        print('df_matched_final size: {}'.format(df_matched.shape))\n",
    "    \n",
    "    return df_matched "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_text</th>\n",
       "      <th>matched</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25855</th>\n",
       "      <td>Barbara Broccoli</td>\n",
       "      <td>BARBARA BROCCOLI</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39192</th>\n",
       "      <td>Ms Choi</td>\n",
       "      <td>President Choi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>CONDADO DE HILLSBOROUGH</td>\n",
       "      <td>Condado de Hillsborough</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>Sidney Madden</td>\n",
       "      <td>SIDNEY MADDEN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Beaver Dam</td>\n",
       "      <td>BEAVER DAM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39092</th>\n",
       "      <td>Ari Shapiro</td>\n",
       "      <td>ARI SHAPIRO</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48886</th>\n",
       "      <td>CHRISTIAN LENGES</td>\n",
       "      <td>Christian Lenges</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30713</th>\n",
       "      <td>JEREMIAH JOHNSON</td>\n",
       "      <td>Jeremiah Johnson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24447</th>\n",
       "      <td>Ms. Verma</td>\n",
       "      <td>Dr. Verma</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>Pero la</td>\n",
       "      <td>Pero La</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28583</th>\n",
       "      <td>CLARENCE AVANT</td>\n",
       "      <td>Clarence Avant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>Paris-Charles de Gaulle</td>\n",
       "      <td>Paris Charles de Gaulle</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22313</th>\n",
       "      <td>bono</td>\n",
       "      <td>Bono</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31339</th>\n",
       "      <td>CONDADO DE SUFFOLK</td>\n",
       "      <td>Condado de Suffolk</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14791</th>\n",
       "      <td>KEVIN LYNCH</td>\n",
       "      <td>Kevin Lynch</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25717</th>\n",
       "      <td>Mr. Bucher</td>\n",
       "      <td>Mrs. Bucher</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28491</th>\n",
       "      <td>Steve Carell</td>\n",
       "      <td>STEVE CARELL</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30617</th>\n",
       "      <td>Jeff McInnis</td>\n",
       "      <td>Jeff Mcinnis</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>Nathan Anslow</td>\n",
       "      <td>NATHAN ANSLOW</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45874</th>\n",
       "      <td>KIMBEL CARTER</td>\n",
       "      <td>Kimbel Carter</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       in_text                  matched  similarity\n",
       "25855         Barbara Broccoli         BARBARA BROCCOLI         1.0\n",
       "39192                  Ms Choi           President Choi         1.0\n",
       "17333  CONDADO DE HILLSBOROUGH  Condado de Hillsborough         1.0\n",
       "39096            Sidney Madden            SIDNEY MADDEN         1.0\n",
       "307                 Beaver Dam               BEAVER DAM         1.0\n",
       "39092              Ari Shapiro              ARI SHAPIRO         1.0\n",
       "48886         CHRISTIAN LENGES         Christian Lenges         1.0\n",
       "30713         JEREMIAH JOHNSON         Jeremiah Johnson         1.0\n",
       "24447                Ms. Verma                Dr. Verma         1.0\n",
       "1437                   Pero la                  Pero La         1.0\n",
       "28583           CLARENCE AVANT           Clarence Avant         1.0\n",
       "3763   Paris-Charles de Gaulle  Paris Charles de Gaulle         1.0\n",
       "22313                     bono                     Bono         1.0\n",
       "31339       CONDADO DE SUFFOLK       Condado de Suffolk         1.0\n",
       "14791              KEVIN LYNCH              Kevin Lynch         1.0\n",
       "25717               Mr. Bucher              Mrs. Bucher         1.0\n",
       "28491             Steve Carell             STEVE CARELL         1.0\n",
       "30617             Jeff McInnis             Jeff Mcinnis         1.0\n",
       "5649             Nathan Anslow            NATHAN ANSLOW         1.0\n",
       "45874            KIMBEL CARTER            Kimbel Carter         1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = get_simliar_names_by_tfdif(persons, threshold=0.7)\n",
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2588, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-letter matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_unicode_to_ascii(data, lowercasing=True):\n",
    "    normal = unicodedata.normalize('NFKD', data).encode('ASCII', 'ignore')\n",
    "    val = normal.decode(\"utf-8\")\n",
    "    if lowercasing:\n",
    "        val = val.lower()\n",
    "    # remove special characters\n",
    "    val = re.sub('[^A-Za-z0-9 ]+', ' ', val)\n",
    "    # remove multiple spaces\n",
    "    val = re.sub(' +', ' ', val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_letters(word, sorting=False, prefix2remove=prefixes_all):\n",
    "    if prefix2remove:  \n",
    "        for prefix in prefix2remove:\n",
    "            word = word.replace(prefix, '')\n",
    "        #word = word[1:] if word[0] == ' ' else word # remove any starting white space\n",
    "    #print(word)\n",
    "    val = normalize_unicode_to_ascii(word, lowercasing=False)      \n",
    "    parts = val if val.isupper() and ' ' not in val else val.split() # don't split if val itself is an acronym\n",
    "    \n",
    "    res = [p[0].lower() for p in parts]\n",
    "    if sorting:\n",
    "        res.sort()\n",
    "    \n",
    "    return \"\".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1st_letters_match(A_iter, B_iter, sorting=False, partial_match=False, prefix2remove=prefixes_all):\n",
    "    '''\n",
    "    param:\n",
    "        A_iter, B_iter: iterable with same length\n",
    "    return:\n",
    "        list of boolean values\n",
    "    '''\n",
    "    assert len(A_iter) == len(B_iter)\n",
    "    \n",
    "    res = list()\n",
    "    for tp in zip(A_iter, B_iter):\n",
    "        first_letters_A = first_letters(tp[0]\n",
    "                                        , sorting=sorting\n",
    "                                        , prefix2remove=prefix2remove\n",
    "                                       )\n",
    "        \n",
    "        first_letters_B = first_letters(tp[1]\n",
    "                                        , sorting=sorting\n",
    "                                        , prefix2remove=prefix2remove\n",
    "                                       )\n",
    "\n",
    "        if len(first_letters_B) < len(first_letters_A):\n",
    "            first_letters_A, first_letters_B = first_letters_B, first_letters_A\n",
    "        \n",
    "        #print(first_letters_A)\n",
    "        #print(first_letters_B)\n",
    "        \n",
    "        if partial_match:\n",
    "            if first_letters_A in first_letters_B:\n",
    "                res.append(True)\n",
    "            else:\n",
    "                res.append(False)\n",
    "        else:\n",
    "            if first_letters_A == first_letters_B:\n",
    "                res.append(True)\n",
    "            else:\n",
    "                res.append(False)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letter_match = get_1st_letters_match(df_test.in_text, df_test.matched, sorting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"first_letter_match\"] = first_letter_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_text</th>\n",
       "      <th>matched</th>\n",
       "      <th>similarity</th>\n",
       "      <th>first_letter_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25855</th>\n",
       "      <td>Barbara Broccoli</td>\n",
       "      <td>BARBARA BROCCOLI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39192</th>\n",
       "      <td>Ms Choi</td>\n",
       "      <td>President Choi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>CONDADO DE HILLSBOROUGH</td>\n",
       "      <td>Condado de Hillsborough</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>Sidney Madden</td>\n",
       "      <td>SIDNEY MADDEN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Beaver Dam</td>\n",
       "      <td>BEAVER DAM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       in_text                  matched  similarity  \\\n",
       "25855         Barbara Broccoli         BARBARA BROCCOLI         1.0   \n",
       "39192                  Ms Choi           President Choi         1.0   \n",
       "17333  CONDADO DE HILLSBOROUGH  Condado de Hillsborough         1.0   \n",
       "39096            Sidney Madden            SIDNEY MADDEN         1.0   \n",
       "307                 Beaver Dam               BEAVER DAM         1.0   \n",
       "\n",
       "       first_letter_match  \n",
       "25855                True  \n",
       "39192                True  \n",
       "17333                True  \n",
       "39096                True  \n",
       "307                  True  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-document ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entity_origin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2739f3e64e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m def co_document_ratio(word_pair, entity_type\n\u001b[0;32m----> 2\u001b[0;31m                       \u001b[0;34m,\u001b[0m \u001b[0mentity_subtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentity_origin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                       \u001b[0;34m,\u001b[0m \u001b[0mcorpusInfo_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscovery_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0;34m,\u001b[0m \u001b[0mby_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      ):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'entity_origin' is not defined"
     ]
    }
   ],
   "source": [
    "def co_document_ratio(word_pair, entity_type\n",
    "                      , entity_subtypes=[], origin=entity_origin\n",
    "                      , corpusInfo_dict = discovery_res\n",
    "                      , by_file=True\n",
    "                     ):\n",
    "    \n",
    "    assert entity_type != None\n",
    "    assert type(entity_subtypes) == list\n",
    "    \n",
    "    name1, name2 = word_pair\n",
    "    origin_name1 = list()\n",
    "    origin_name2 = list()\n",
    "    \n",
    "    if entity_subtypes:\n",
    "        for subtype in entity_subtypes:\n",
    "            origin_name1.extend(origin[name1][(entity_type, subtype)])\n",
    "            origin_name2.extend(origin[name2][(entity_type, subtype)])\n",
    "    else: # subtypes not designated\n",
    "        keys1 = [key for key in origin[name1].keys() if key[0] == entity_type]\n",
    "        keys2 = [key for key in origin[name2].keys() if key[0] == entity_type]\n",
    "        \n",
    "        for key in keys1:\n",
    "            origin_name1.extend(origin[name1][key])\n",
    "        \n",
    "        for key in keys2:\n",
    "            origin_name2.extend(origin[name2][key])\n",
    "    \n",
    "    doc_ids_1 = set()\n",
    "    for seg_id in origin_name1:\n",
    "        if by_file:\n",
    "            # this is .pdf filename, i.e. document name\n",
    "            filename = corpusInfo_dict[seg_id]['filename']\n",
    "\n",
    "        else: \n",
    "            # this is .json filename i.e. paragraph name\n",
    "            filename = corpusInfo_dict[seg_id]['extracted_metadata']['filename']\n",
    "        \n",
    "        doc_ids_1.add(filename)\n",
    "        \n",
    "    doc_ids_2 = set()\n",
    "    for seg_id in origin_name2:\n",
    "        if by_file:\n",
    "            # this is .pdf filename, i.e. document name\n",
    "            filename = corpusInfo_dict[seg_id]['filename']\n",
    "\n",
    "        else: \n",
    "            # this is .json filename i.e. paragraph name\n",
    "            filename = corpusInfo_dict[seg_id]['extracted_metadata']['filename']\n",
    "        \n",
    "        doc_ids_2.add(filename)\n",
    "    \n",
    "    #doc_ids_1=set([s.split('_')[0] for s in origin_name1])\n",
    "    #doc_ids_2=set([s.split('_')[0] for s in origin_name2])\n",
    "    \n",
    "    doc_ids_common = doc_ids_1.intersection(doc_ids_2)\n",
    "    \n",
    "    #print(doc_ids_1)\n",
    "    #print(doc_ids_2)\n",
    "    #print(doc_ids_common)\n",
    "    \n",
    "    if not doc_ids_common:\n",
    "        return 0.\n",
    "    else:\n",
    "        return len(doc_ids_common)/(len(doc_ids_1)+len(doc_ids_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_co_document_ratio(A_iter, B_iter, entity_type, entity_subtypes=[], origin=entity_origin, by_file=True):\n",
    "    '''\n",
    "    param:\n",
    "        A_iter, B_iter: iterable with same length\n",
    "    return:\n",
    "        lists of co-document ratio \n",
    "    '''\n",
    "    assert len(A_iter) == len(B_iter)\n",
    "    \n",
    "    res = list()\n",
    "    for tp in zip(A_iter, B_iter):\n",
    "        co_doc_ratio = co_document_ratio(tp\n",
    "                                         , entity_type=entity_type\n",
    "                                         , entity_subtypes=entity_subtypes\n",
    "                                         , origin=origin\n",
    "                                         , by_file=by_file\n",
    "                                        )\n",
    "        res.append(co_doc_ratio)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_doc_ratio = get_co_document_ratio(df_test.in_text, df_test.matched, entity_type='Person', by_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"co_doc_ratio\"] = co_doc_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous\n",
    "- Nonlinear double-metaphone matching scores\n",
    "- inverse-Levenshtein distance\n",
    "- Jaro-Winker distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_doublemetaphone(word_pair, normalize2Ascii=True, prefix2remove=prefixes_all):\n",
    "    '''\n",
    "    ToDo: function description\n",
    "    '''\n",
    "    w1, w2 = word_pair\n",
    "    \n",
    "    if prefix2remove:  \n",
    "        for prefix in prefix2remove:\n",
    "            w1 = w1.replace(prefix, '')\n",
    "            w2 = w2.replace(prefix, '')\n",
    "    \n",
    "        # remove any starting white space\n",
    "        #w1 = w1[1:] if w1[0] == ' ' else w1\n",
    "        #w2 = w2[1:] if w2[0] == ' ' else w2\n",
    "    \n",
    "    match_types = ['ASCII_norm_match', 'strong_match', 'weak_match', 'minimal_match', 'no_match']\n",
    "    \n",
    "    if normalize2Ascii:\n",
    "        w1, w2 = tuple(map(normalize_unicode_to_ascii, (w1, w2)))\n",
    "        if w1 == w2:\n",
    "            return (True, match_types[0], (None, None))\n",
    "    else:\n",
    "        w1, w2 = word_pair\n",
    "    \n",
    "    tp1 = dmt_phone(w1)\n",
    "    tp2 = dmt_phone(w2)\n",
    "    \n",
    "    match = True\n",
    "    if tp1[0] == tp2[0]: # primary_key match\n",
    "        match_type = match_types[1]\n",
    "    elif tp1[0] == tp2[1] or tp1[1] == tp2[0]: # secondary_key == primary_key or vise versa\n",
    "        match_type = match_types[2]\n",
    "    elif tp1[1] == tp2[1]: # secondary_key == secondary_key\n",
    "        match_type = match_types[3]\n",
    "    else:\n",
    "        match, match_type = False, match_types[4]\n",
    "    \n",
    "    return (match, match_type, (tp1, tp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, a=1):\n",
    "    return 1/(1 + np.exp(-a*x))\n",
    "\n",
    "def dmtph_match_score(x):\n",
    "    '''\n",
    "    This function gives rewards for \"ascii_norm_match\" & \"strong_match\", but penalties for the rest\n",
    "    i.e. non-linear weighting\n",
    "    '''\n",
    "    return sigmoid(20*(x-0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dmtph_match(A_iter, B_iter, prefix2remove=prefixes_all):\n",
    "    '''\n",
    "    param:\n",
    "        A_iter, B_iter: iterable with same length\n",
    "    return:\n",
    "        list of match scores\n",
    "    '''\n",
    "    assert len(A_iter) == len(B_iter)\n",
    "    \n",
    "    match_types = ['ASCII_norm_match', 'strong_match', 'weak_match', 'minimal_match', 'no_match']\n",
    "    match_types.reverse()\n",
    "    x = np.linspace(0, 1, 5)\n",
    "\n",
    "    res = list()\n",
    "    for tp in zip(A_iter, B_iter):\n",
    "        match, match_type, dummy = match_doublemetaphone(tp, prefix2remove=prefix2remove)\n",
    "        match_score = dmtph_match_score(x[match_types.index(match_type)])\n",
    "        res.append(match_score)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmtph_match = get_dmtph_match(df_test.in_text, df_test.matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"dmtph_match\"] = dmtph_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_text</th>\n",
       "      <th>matched</th>\n",
       "      <th>similarity</th>\n",
       "      <th>first_letter_match</th>\n",
       "      <th>dmtph_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25855</th>\n",
       "      <td>Barbara Broccoli</td>\n",
       "      <td>BARBARA BROCCOLI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39192</th>\n",
       "      <td>Ms Choi</td>\n",
       "      <td>President Choi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>CONDADO DE HILLSBOROUGH</td>\n",
       "      <td>Condado de Hillsborough</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>Sidney Madden</td>\n",
       "      <td>SIDNEY MADDEN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Beaver Dam</td>\n",
       "      <td>BEAVER DAM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       in_text                  matched  similarity  \\\n",
       "25855         Barbara Broccoli         BARBARA BROCCOLI         1.0   \n",
       "39192                  Ms Choi           President Choi         1.0   \n",
       "17333  CONDADO DE HILLSBOROUGH  Condado de Hillsborough         1.0   \n",
       "39096            Sidney Madden            SIDNEY MADDEN         1.0   \n",
       "307                 Beaver Dam               BEAVER DAM         1.0   \n",
       "\n",
       "       first_letter_match  dmtph_match  \n",
       "25855                True     0.997527  \n",
       "39192                True     0.997527  \n",
       "17333                True     0.997527  \n",
       "39096                True     0.997527  \n",
       "307                  True     0.997527  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_distance(A_iter, B_iter, normalize=True, prefix2remove=prefixes_all):\n",
    "    '''\n",
    "    param:\n",
    "        A_iter, B_iter: iterable with same length\n",
    "    return:\n",
    "        lists of invese-Levenshtein distance & Jaro-Winkler distance, respectively \n",
    "    '''\n",
    "    assert len(A_iter) == len(B_iter)\n",
    "    \n",
    "    res_inv_lvst = list()\n",
    "    res_jw = list()\n",
    "    for w1, w2 in zip(A_iter, B_iter):\n",
    "        if prefix2remove:  \n",
    "            for prefix in prefix2remove:\n",
    "                w1 = w1.replace(prefix, '')\n",
    "                w2 = w2.replace(prefix, '')\n",
    "        \n",
    "            # remove any starting white space\n",
    "            #w1 = w1[1:] if w1[0] == ' ' else w1\n",
    "            #w2 = w2[1:] if w2[0] == ' ' else w2\n",
    "        \n",
    "        if normalize:\n",
    "            w1, w2 = tuple(map(normalize_unicode_to_ascii, (w1, w2)))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        inv_lvst_dist = 1/lvst.distance(w1, w2) if lvst.distance(w1, w2) else 1 # avoid dividing by zero\n",
    "        jw_dist = lvst.jaro_winkler(w1, w2)\n",
    "        res_inv_lvst.append(inv_lvst_dist)\n",
    "        res_jw.append(jw_dist)\n",
    "    \n",
    "    return res_inv_lvst, res_jw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_lvst_dist, jw_dist = get_string_distance(df_test.in_text, df_test.matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"inv_lvst_dist\"] = inv_lvst_dist\n",
    "df_test[\"jw_dist\"] = jw_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_text</th>\n",
       "      <th>matched</th>\n",
       "      <th>similarity</th>\n",
       "      <th>first_letter_match</th>\n",
       "      <th>dmtph_match</th>\n",
       "      <th>inv_lvst_dist</th>\n",
       "      <th>jw_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25855</th>\n",
       "      <td>Barbara Broccoli</td>\n",
       "      <td>BARBARA BROCCOLI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39192</th>\n",
       "      <td>Ms Choi</td>\n",
       "      <td>President Choi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>CONDADO DE HILLSBOROUGH</td>\n",
       "      <td>Condado de Hillsborough</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>Sidney Madden</td>\n",
       "      <td>SIDNEY MADDEN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Beaver Dam</td>\n",
       "      <td>BEAVER DAM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       in_text                  matched  similarity  \\\n",
       "25855         Barbara Broccoli         BARBARA BROCCOLI         1.0   \n",
       "39192                  Ms Choi           President Choi         1.0   \n",
       "17333  CONDADO DE HILLSBOROUGH  Condado de Hillsborough         1.0   \n",
       "39096            Sidney Madden            SIDNEY MADDEN         1.0   \n",
       "307                 Beaver Dam               BEAVER DAM         1.0   \n",
       "\n",
       "       first_letter_match  dmtph_match  inv_lvst_dist  jw_dist  \n",
       "25855                True     0.997527            1.0      1.0  \n",
       "39192                True     0.997527            1.0      1.0  \n",
       "17333                True     0.997527            1.0      1.0  \n",
       "39096                True     0.997527            1.0      1.0  \n",
       "307                  True     0.997527            1.0      1.0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2588"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper\n",
    "\n",
    "All algo at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_match(entity_names, entity_type, entity_subtypes=[]\n",
    "                 , wiki_match=False\n",
    "                 , prefix2remove=prefixes_all\n",
    "                 , sorting_1st_letters=False\n",
    "                 , partial_1st_letter_match=False\n",
    "                 , co_doc_by_file=True       \n",
    "                ):\n",
    "    \n",
    "    df = get_simliar_names_by_tfdif(entity_names)\n",
    "    \n",
    "    print(\"# of candidate pairs: {}\".format(df.shape[0]))\n",
    "    if wiki_match:\n",
    "        df[\"wiki_match\"] = get_wiki_match(df.in_text, df.matched)\n",
    "    \n",
    "    df[\"first_letter_match\"] = get_1st_letters_match(df.in_text, df.matched\n",
    "                                                     , sorting=sorting_1st_letters\n",
    "                                                     , partial_match=partial_1st_letter_match\n",
    "                                                     , prefix2remove=prefix2remove\n",
    "                                                    )\n",
    "    \n",
    "#     df[\"co_doc_ratio\"] = get_co_document_ratio(df.in_text, df.matched\n",
    "#                                                , entity_type=entity_type\n",
    "#                                                , entity_subtypes=entity_subtypes\n",
    "#                                                , by_file=co_doc_by_file      \n",
    "#                                               )\n",
    "    \n",
    "    df[\"dmtph_match\"] = get_dmtph_match(df.in_text, df.matched, prefix2remove=prefix2remove)\n",
    "    \n",
    "    inv_lvst_dist, jw_dist = get_string_distance(df.in_text, df.matched, prefix2remove=prefix2remove)\n",
    "    df[\"inv_lvst_dist\"] = inv_lvst_dist\n",
    "    df[\"jw_sim\"] = jw_dist # in python Levenshtein library, this is actually simlarity ranging [0, 1]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of candidate pairs: 2588\n"
     ]
    }
   ],
   "source": [
    "df_test = get_df_match(persons, 'Person', sorting_1st_letters=True, partial_1st_letter_match=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_text</th>\n",
       "      <th>matched</th>\n",
       "      <th>similarity</th>\n",
       "      <th>first_letter_match</th>\n",
       "      <th>dmtph_match</th>\n",
       "      <th>inv_lvst_dist</th>\n",
       "      <th>jw_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25855</th>\n",
       "      <td>Barbara Broccoli</td>\n",
       "      <td>BARBARA BROCCOLI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39192</th>\n",
       "      <td>Ms Choi</td>\n",
       "      <td>President Choi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>CONDADO DE HILLSBOROUGH</td>\n",
       "      <td>Condado de Hillsborough</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>Sidney Madden</td>\n",
       "      <td>SIDNEY MADDEN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Beaver Dam</td>\n",
       "      <td>BEAVER DAM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       in_text                  matched  similarity  \\\n",
       "25855         Barbara Broccoli         BARBARA BROCCOLI         1.0   \n",
       "39192                  Ms Choi           President Choi         1.0   \n",
       "17333  CONDADO DE HILLSBOROUGH  Condado de Hillsborough         1.0   \n",
       "39096            Sidney Madden            SIDNEY MADDEN         1.0   \n",
       "307                 Beaver Dam               BEAVER DAM         1.0   \n",
       "\n",
       "       first_letter_match  dmtph_match  inv_lvst_dist  jw_sim  \n",
       "25855                True     0.997527            1.0     1.0  \n",
       "39192                True     0.997527            1.0     1.0  \n",
       "17333                True     0.997527            1.0     1.0  \n",
       "39096                True     0.997527            1.0     1.0  \n",
       "307                  True     0.997527            1.0     1.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted average of matchings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_match(df, weights=[]):\n",
    "    '''\n",
    "    get a weighted average of matching scores\n",
    "    '''\n",
    "    row_num = df.shape[0]\n",
    "    matchings = df.columns[2:]\n",
    "    if weights:\n",
    "        assert len(weights) == len(matchings)\n",
    "        weights = np.array(weights)\n",
    "    else:\n",
    "        weights = np.ones(len(matchings))\n",
    "    \n",
    "    match_score = pd.Series(np.zeros(row_num), dtype='float64')\n",
    "    for weight, matching in zip(weights, matchings):\n",
    "        match_score += weight*df[matching]\n",
    "    \n",
    "    match_score = match_score/weights.sum()\n",
    "    \n",
    "    return match_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_match_score(df, weights=[]):\n",
    "    if 'match_score' in df.columns:\n",
    "        df.drop(['match_score'], axis=1, inplace=True)\n",
    "    df['match_score'] = get_ensemble_match(df, weights=weights)\n",
    "    df.sort_values(by='match_score', ascending=False, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_person = [4,2,1,1,1]\n",
    "add_match_score(df_test, weights=weights_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_text</th>\n",
       "      <th>matched</th>\n",
       "      <th>similarity</th>\n",
       "      <th>first_letter_match</th>\n",
       "      <th>dmtph_match</th>\n",
       "      <th>inv_lvst_dist</th>\n",
       "      <th>jw_sim</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beaver Dam</td>\n",
       "      <td>BEAVER DAM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Trump's</td>\n",
       "      <td>Mr. Trump's</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pero la</td>\n",
       "      <td>Pero La</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brian Mahoney</td>\n",
       "      <td>BRIAN MAHONEY</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kim Jong-un</td>\n",
       "      <td>Kim Jong Un</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NADIA BOULANGER</td>\n",
       "      <td>Nadia Boulanger</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gov DeWine</td>\n",
       "      <td>Gov. DeWine</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLANT SALE</td>\n",
       "      <td>Plant Sale</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEAR ABBY</td>\n",
       "      <td>Dear Abby</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bill de Blasio's</td>\n",
       "      <td>Bill De Blasio's</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>President Trump's</td>\n",
       "      <td>Mrs. Trump's</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Beethoven</td>\n",
       "      <td>BEETHOVEN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>President Carter</td>\n",
       "      <td>Mr. Carter</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ms. Jones</td>\n",
       "      <td>Mrs. Jones</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ms. Jones</td>\n",
       "      <td>Mr. Jones</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rihanna</td>\n",
       "      <td>RIHANNA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>President Trump</td>\n",
       "      <td>Mr. Trump</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>LADY GAGA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>JOE BIDEN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dr Shah</td>\n",
       "      <td>Dr. Shah</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mr. Cohen</td>\n",
       "      <td>Dr. Cohen</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Steve McQueen</td>\n",
       "      <td>STEVE MCQUEEN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>President Trump</td>\n",
       "      <td>Mrs. Trump</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ALMA MAHLER</td>\n",
       "      <td>Alma Mahler</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BEEKMAN STREET ART FAIR</td>\n",
       "      <td>Beekman Street Art Fair</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Brenda Bethune</td>\n",
       "      <td>BRENDA BETHUNE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ADIRONDACK WINE</td>\n",
       "      <td>Adirondack Wine</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TROY NIGHT OUT</td>\n",
       "      <td>Troy Night Out</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.975274e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Drew Brees</td>\n",
       "      <td>Drew Brees'</td>\n",
       "      <td>0.931466</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.938835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Martin Luther King</td>\n",
       "      <td>Dr. Martin Luther King</td>\n",
       "      <td>0.953449</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852827</td>\n",
       "      <td>0.933076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Fair Board</td>\n",
       "      <td>Fair Board President</td>\n",
       "      <td>0.912691</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Kareem Abdul-Jabbar</td>\n",
       "      <td>Kareem Abdul Jabar</td>\n",
       "      <td>0.892218</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Brian Douglass</td>\n",
       "      <td>Brian Douglas</td>\n",
       "      <td>0.891054</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>Christiano Ronaldo</td>\n",
       "      <td>0.864829</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.908190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Robert Cooke</td>\n",
       "      <td>Robert Cook</td>\n",
       "      <td>0.821002</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>Breonne Taylor</td>\n",
       "      <td>0.826221</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965568</td>\n",
       "      <td>0.889057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Valerie Arkoosh</td>\n",
       "      <td>Valerie A. Arkoosh</td>\n",
       "      <td>0.935304</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.885372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Don Nelson</td>\n",
       "      <td>Dan Nelson</td>\n",
       "      <td>0.787634</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.869066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Antonio Guterres</td>\n",
       "      <td>Antnio Guterres</td>\n",
       "      <td>0.773624</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962083</td>\n",
       "      <td>0.865293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>John McCrae</td>\n",
       "      <td>John McRae</td>\n",
       "      <td>0.762383</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.863500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Nic Davis</td>\n",
       "      <td>Nic Davies</td>\n",
       "      <td>0.729937</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.849349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Steven Mnuchin</td>\n",
       "      <td>Steve Mnuchin</td>\n",
       "      <td>0.883249</td>\n",
       "      <td>True</td>\n",
       "      <td>8.315280e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936813</td>\n",
       "      <td>0.829979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Susan Clark</td>\n",
       "      <td>Susanna Clark</td>\n",
       "      <td>0.811411</td>\n",
       "      <td>True</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.824529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Abraham Lincoln's</td>\n",
       "      <td>0.970880</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ahmaud Arbery</td>\n",
       "      <td>Ahmaud Arbery's</td>\n",
       "      <td>0.965038</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Noah Gragson's</td>\n",
       "      <td>Noah Gragson</td>\n",
       "      <td>0.964241</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Christopher Nolan's</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>0.963926</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Asa Hutchinson</td>\n",
       "      <td>Asa Hutchinson's</td>\n",
       "      <td>0.963812</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Derek Chauvin</td>\n",
       "      <td>Derek Chauvin's</td>\n",
       "      <td>0.962639</td>\n",
       "      <td>True</td>\n",
       "      <td>8.315280e-07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Denver Bazaar</td>\n",
       "      <td>Denver Bazaar's</td>\n",
       "      <td>0.962570</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    in_text                  matched  similarity  \\\n",
       "0                Beaver Dam               BEAVER DAM    1.000000   \n",
       "1         President Trump's              Mr. Trump's    1.000000   \n",
       "2                   Pero la                  Pero La    1.000000   \n",
       "3             Brian Mahoney            BRIAN MAHONEY    1.000000   \n",
       "4               Kim Jong-un              Kim Jong Un    1.000000   \n",
       "5           NADIA BOULANGER          Nadia Boulanger    1.000000   \n",
       "6                Gov DeWine              Gov. DeWine    1.000000   \n",
       "7                PLANT SALE               Plant Sale    1.000000   \n",
       "8                 DEAR ABBY                Dear Abby    1.000000   \n",
       "9          Bill de Blasio's         Bill De Blasio's    1.000000   \n",
       "10        President Trump's             Mrs. Trump's    1.000000   \n",
       "11                Beethoven                BEETHOVEN    1.000000   \n",
       "12         President Carter               Mr. Carter    1.000000   \n",
       "13                Ms. Jones               Mrs. Jones    1.000000   \n",
       "14                Ms. Jones                Mr. Jones    1.000000   \n",
       "15                  Rihanna                  RIHANNA    1.000000   \n",
       "16          President Trump                Mr. Trump    1.000000   \n",
       "17                Lady Gaga                LADY GAGA    1.000000   \n",
       "18                Joe Biden                JOE BIDEN    1.000000   \n",
       "19                  Dr Shah                 Dr. Shah    1.000000   \n",
       "20                Mr. Cohen                Dr. Cohen    1.000000   \n",
       "21            Steve McQueen            STEVE MCQUEEN    1.000000   \n",
       "22          President Trump               Mrs. Trump    1.000000   \n",
       "23              ALMA MAHLER              Alma Mahler    1.000000   \n",
       "24  BEEKMAN STREET ART FAIR  Beekman Street Art Fair    1.000000   \n",
       "25           Brenda Bethune           BRENDA BETHUNE    1.000000   \n",
       "26          ADIRONDACK WINE          Adirondack Wine    1.000000   \n",
       "27           TROY NIGHT OUT           Troy Night Out    1.000000   \n",
       "28               Drew Brees              Drew Brees'    0.931466   \n",
       "29       Martin Luther King   Dr. Martin Luther King    0.953449   \n",
       "30               Fair Board     Fair Board President    0.912691   \n",
       "31      Kareem Abdul-Jabbar       Kareem Abdul Jabar    0.892218   \n",
       "32           Brian Douglass            Brian Douglas    0.891054   \n",
       "33        Cristiano Ronaldo       Christiano Ronaldo    0.864829   \n",
       "34             Robert Cooke              Robert Cook    0.821002   \n",
       "35           Breonna Taylor           Breonne Taylor    0.826221   \n",
       "36          Valerie Arkoosh       Valerie A. Arkoosh    0.935304   \n",
       "37               Don Nelson               Dan Nelson    0.787634   \n",
       "38         Antonio Guterres          Antnio Guterres    0.773624   \n",
       "39              John McCrae               John McRae    0.762383   \n",
       "40                Nic Davis               Nic Davies    0.729937   \n",
       "41           Steven Mnuchin            Steve Mnuchin    0.883249   \n",
       "42              Susan Clark            Susanna Clark    0.811411   \n",
       "43          Abraham Lincoln        Abraham Lincoln's    0.970880   \n",
       "44            Ahmaud Arbery          Ahmaud Arbery's    0.965038   \n",
       "45           Noah Gragson's             Noah Gragson    0.964241   \n",
       "46      Christopher Nolan's        Christopher Nolan    0.963926   \n",
       "47           Asa Hutchinson         Asa Hutchinson's    0.963812   \n",
       "48            Derek Chauvin          Derek Chauvin's    0.962639   \n",
       "49            Denver Bazaar          Denver Bazaar's    0.962570   \n",
       "\n",
       "    first_letter_match   dmtph_match  inv_lvst_dist    jw_sim  match_score  \n",
       "0                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "1                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "2                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "3                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "4                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "5                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "6                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "7                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "8                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "9                 True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "10                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "11                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "12                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "13                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "14                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "15                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "16                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "17                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "18                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "19                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "20                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "21                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "22                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "23                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "24                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "25                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "26                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "27                True  9.975274e-01            1.0  1.000000     0.999725  \n",
       "28                True  7.310586e-01            1.0  0.992593     0.938835  \n",
       "29                True  7.310586e-01            1.0  0.852827     0.933076  \n",
       "30                True  7.310586e-01            1.0  1.000000     0.931314  \n",
       "31                True  7.310586e-01            1.0  1.000000     0.922215  \n",
       "32                True  7.310586e-01            1.0  1.000000     0.921697  \n",
       "33                True  7.310586e-01            1.0  0.983333     0.908190  \n",
       "34                True  7.310586e-01            1.0  1.000000     0.890563  \n",
       "35                True  7.310586e-01            1.0  0.965568     0.889057  \n",
       "36                True  7.310586e-01            0.5  0.996078     0.885372  \n",
       "37                True  7.310586e-01            1.0  0.940000     0.869066  \n",
       "38                True  7.310586e-01            1.0  0.962083     0.865293  \n",
       "39                True  7.310586e-01            1.0  0.990909     0.863500  \n",
       "40                True  7.310586e-01            1.0  0.993333     0.849349  \n",
       "41                True  8.315280e-07            1.0  0.936813     0.829979  \n",
       "42                True  7.310586e-01            0.5  0.944056     0.824529  \n",
       "43                True  1.233946e-04            0.5  1.000000     0.820405  \n",
       "44                True  1.233946e-04            0.5  1.000000     0.817808  \n",
       "45                True  1.233946e-04            0.5  1.000000     0.817454  \n",
       "46                True  1.233946e-04            0.5  1.000000     0.817314  \n",
       "47                True  1.233946e-04            0.5  1.000000     0.817264  \n",
       "48                True  8.315280e-07            0.5  1.000000     0.816729  \n",
       "49                True  1.233946e-04            0.5  1.000000     0.816711  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    206.000000\n",
       "mean       0.718828\n",
       "std        0.175420\n",
       "min        0.394210\n",
       "25%        0.593098\n",
       "50%        0.735240\n",
       "75%        0.815751\n",
       "max        0.999725\n",
       "Name: match_score, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.match_score.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_off(df, q=None, lower_bound=0.0):\n",
    "    assert lower_bound >= 0.0 and lower_bound <= 1.0\n",
    "    if not lower_bound:\n",
    "        if not q:\n",
    "            return df[df.match_score > df.match_score.mean()]\n",
    "        else:\n",
    "            assert type(q) == float\n",
    "            return df[df.match_score > df.match_score.quantile(q)]\n",
    "    else: # given nonzero lowever bound, use it as a filter\n",
    "        eps = 1e-10\n",
    "        return df[df.match_score >= lower_bound-eps] # inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match = cut_off(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2588, 8)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 8)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_text</th>\n",
       "      <th>matched</th>\n",
       "      <th>similarity</th>\n",
       "      <th>first_letter_match</th>\n",
       "      <th>dmtph_match</th>\n",
       "      <th>inv_lvst_dist</th>\n",
       "      <th>jw_sim</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Benjamin Harris</td>\n",
       "      <td>Benjamin Hardin</td>\n",
       "      <td>0.779806</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Robert Kennedy</td>\n",
       "      <td>Robert F. Kennedy</td>\n",
       "      <td>0.781836</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.734996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Madeleine \"Maddie\" McCann</td>\n",
       "      <td>Madeleine McCann</td>\n",
       "      <td>0.866477</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Al Gore Sr</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>0.820867</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.731881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Joe Garcia</td>\n",
       "      <td>Joe L. Garcia</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>True</td>\n",
       "      <td>8.315280e-07</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.731384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       in_text            matched  similarity  \\\n",
       "102            Benjamin Harris    Benjamin Hardin    0.779806   \n",
       "103             Robert Kennedy  Robert F. Kennedy    0.781836   \n",
       "104  Madeleine \"Maddie\" McCann   Madeleine McCann    0.866477   \n",
       "105                 Al Gore Sr            Al Gore    0.820867   \n",
       "106                 Joe Garcia      Joe L. Garcia    0.778947   \n",
       "\n",
       "     first_letter_match   dmtph_match  inv_lvst_dist    jw_sim  match_score  \n",
       "102                True  1.233946e-04       0.500000  1.000000     0.735483  \n",
       "103                True  1.233946e-04       0.500000  0.987500     0.734996  \n",
       "104                True  1.233946e-04       0.142857  1.000000     0.734321  \n",
       "105                True  1.233946e-04       0.333333  0.970000     0.731881  \n",
       "106                True  8.315280e-07       0.500000  0.966667     0.731384  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected-Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = list(df_match[[\"in_text\", \"matched\", \"match_score\"]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Beaver Dam', 'BEAVER DAM', 0.9997252640937074),\n",
       " (\"President Trump's\", \"Mr. Trump's\", 0.9997252640937072),\n",
       " ('Pero la', 'Pero La', 0.9997252640937072),\n",
       " ('Brian Mahoney', 'BRIAN MAHONEY', 0.9997252640937072),\n",
       " ('Kim Jong-un', 'Kim Jong Un', 0.9997252640937072)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate graph\n",
    "graph_ = nx.Graph()\n",
    "graph_.add_weighted_edges_from(edge_list)\n",
    "\n",
    "# extract connected components and reverse sort by length of components\n",
    "connected_comp = [c for c in nx.connected_components(graph_)]\n",
    "connected_comp.sort(key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_comp(df):\n",
    "    edge_list = list(df[[\"in_text\", \"matched\", \"match_score\"]].itertuples(index=False, name=None))\n",
    "    graph_ = nx.Graph()\n",
    "    graph_.add_weighted_edges_from(edge_list)\n",
    "\n",
    "    # extract connected components and reverse sort by length of components\n",
    "    connected_comp = [c for c in nx.connected_components(graph_)]\n",
    "    connected_comp.sort(key=len, reverse=True)\n",
    "    \n",
    "    return connected_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"Mr. Trump's\", \"Mrs. Trump's\", \"President Trump's\"},\n",
       " {\"Bill De Blasio's\", 'Bill de Blasio', \"Bill de Blasio's\"},\n",
       " {'Mr. Jones', 'Mrs. Jones', 'Ms. Jones'},\n",
       " {'Mr. Trump', 'Mrs. Trump', 'President Trump'},\n",
       " {'Madeleine \"Maddie\" McCann', 'Madeleine McCann', 'van Madeleine McCann'},\n",
       " {'BEAVER DAM', 'Beaver Dam'},\n",
       " {'Pero La', 'Pero la'},\n",
       " {'BRIAN MAHONEY', 'Brian Mahoney'},\n",
       " {'Kim Jong Un', 'Kim Jong-un'},\n",
       " {'NADIA BOULANGER', 'Nadia Boulanger'},\n",
       " {'Gov DeWine', 'Gov. DeWine'},\n",
       " {'PLANT SALE', 'Plant Sale'},\n",
       " {'DEAR ABBY', 'Dear Abby'},\n",
       " {'BEETHOVEN', 'Beethoven'},\n",
       " {'Mr. Carter', 'President Carter'},\n",
       " {'RIHANNA', 'Rihanna'},\n",
       " {'LADY GAGA', 'Lady Gaga'},\n",
       " {'JOE BIDEN', 'Joe Biden'},\n",
       " {'Dr Shah', 'Dr. Shah'},\n",
       " {'Dr. Cohen', 'Mr. Cohen'},\n",
       " {'STEVE MCQUEEN', 'Steve McQueen'},\n",
       " {'ALMA MAHLER', 'Alma Mahler'},\n",
       " {'BEEKMAN STREET ART FAIR', 'Beekman Street Art Fair'},\n",
       " {'BRENDA BETHUNE', 'Brenda Bethune'},\n",
       " {'ADIRONDACK WINE', 'Adirondack Wine'},\n",
       " {'TROY NIGHT OUT', 'Troy Night Out'},\n",
       " {'Drew Brees', \"Drew Brees'\"},\n",
       " {'Dr. Martin Luther King', 'Martin Luther King'},\n",
       " {'Fair Board', 'Fair Board President'},\n",
       " {'Kareem Abdul Jabar', 'Kareem Abdul-Jabbar'},\n",
       " {'Brian Douglas', 'Brian Douglass'},\n",
       " {'Christiano Ronaldo', 'Cristiano Ronaldo'},\n",
       " {'Robert Cook', 'Robert Cooke'},\n",
       " {'Breonna Taylor', 'Breonne Taylor'},\n",
       " {'Valerie A. Arkoosh', 'Valerie Arkoosh'},\n",
       " {'Dan Nelson', 'Don Nelson'},\n",
       " {'Antnio Guterres', 'Antonio Guterres'},\n",
       " {'John McCrae', 'John McRae'},\n",
       " {'Nic Davies', 'Nic Davis'},\n",
       " {'Steve Mnuchin', 'Steven Mnuchin'},\n",
       " {'Susan Clark', 'Susanna Clark'},\n",
       " {'Abraham Lincoln', \"Abraham Lincoln's\"},\n",
       " {'Ahmaud Arbery', \"Ahmaud Arbery's\"},\n",
       " {'Noah Gragson', \"Noah Gragson's\"},\n",
       " {'Christopher Nolan', \"Christopher Nolan's\"},\n",
       " {'Asa Hutchinson', \"Asa Hutchinson's\"},\n",
       " {'Derek Chauvin', \"Derek Chauvin's\"},\n",
       " {'Denver Bazaar', \"Denver Bazaar's\"},\n",
       " {'Lin-Manuel Miranda', \"Lin-Manuel Miranda's\"},\n",
       " {'Michelle Lujan Grisham', \"Michelle Lujan Grisham's\"},\n",
       " {'Barack Obama', \"Barack Obama's\"},\n",
       " {'J.B. Pritzker', \"J.B. Pritzker's\"},\n",
       " {'St. Augustine', \"St. Augustine's\"},\n",
       " {'Jay Inslee', \"Jay Inslee's\"},\n",
       " {'Dennis Rodman', \"Dennis Rodman's\"},\n",
       " {'Lyndon Johnson', \"Lyndon Johnson's\"},\n",
       " {'Blake Shelton', \"Blake Shelton's\"},\n",
       " {'Jimmy Kimmel', \"Jimmy Kimmel's\"},\n",
       " {'Ralph Northam', \"Ralph Northam's\"},\n",
       " {'Gary Bettman', \"Gary Bettman's\"},\n",
       " {'Dan Eatherley', \"Dan Eatherley's\"},\n",
       " {'Phil Jackson', \"Phil Jackson's\"},\n",
       " {'Greg Abbott', \"Greg Abbott's\"},\n",
       " {'Denver Film', \"Denver Film's\"},\n",
       " {'Lujan Grisham', \"Lujan Grisham's\"},\n",
       " {'Paul Cohen', \"Paul Cohen's\"},\n",
       " {'Boris Johnson', \"Boris Johnson's\"},\n",
       " {'Gavin Newsom', \"Gavin Newsom's\"},\n",
       " {'Andrew Cuomo', \"Andrew Cuomo's\"},\n",
       " {'George Floyd', \"George Floyd's\"},\n",
       " {'Frank Herbert', \"Frank Herbert's\"},\n",
       " {'Gov. Northam', \"Gov. Northam's\"},\n",
       " {'Kate Brown', \"Kate Brown's\"},\n",
       " {'John Glenn', \"John Glenn's\"},\n",
       " {'Kevin Stitt', \"Kevin Stitt's\"},\n",
       " {'Roy Cooper', \"Roy Cooper's\"},\n",
       " {'John A. Logan', 'John Logan'},\n",
       " {'David Shaner', \"David Shaner's\"},\n",
       " {'En de', 'En del'},\n",
       " {'Rochelle Stein', 'Rochelle Steiner'},\n",
       " {'Tim Walz', \"Tim Walz's\"},\n",
       " {'Bruce Dern', 'Bruce Dern Bruce Dern'},\n",
       " {'Brandon J. Jones', 'Brandon Jones'},\n",
       " {'N. Park Saturday', 'Park Saturday'},\n",
       " {'Baker MG', 'Mr Baker'},\n",
       " {'Bruce Winten', 'Bruce Winters'},\n",
       " {'Ashley Johnson', 'Ashley Johnson al'},\n",
       " {'Dave Roberts', 'Dave Robertson'},\n",
       " {'Randolph \"Randy\" Reynolds Jr', 'Randolph Reynolds Jr'},\n",
       " {'Dr. Ruiz', 'F. Ruiz'},\n",
       " {'Michael D. Israel', 'Michael Israel'},\n",
       " {'Greta Thunberg', 'di Greta Thunberg'},\n",
       " {'Jenkins', 'T. Jenkins'},\n",
       " {'Zach Collier', 'Zach Collins'},\n",
       " {'Kim Kardashian', 'van Kim Kardashian'},\n",
       " {'Dean Beer', 'Dean M. Beer'},\n",
       " {'Robert Dick', 'Robert Dickson'},\n",
       " {'Leroy Carr', 'Leroy Carter'},\n",
       " {'Benjamin Hardin', 'Benjamin Harris'},\n",
       " {'Robert F. Kennedy', 'Robert Kennedy'},\n",
       " {'Al Gore', 'Al Gore Sr'},\n",
       " {'Joe Garcia', 'Joe L. Garcia'}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definitely simple averaging over matchings are not optimal\n",
    "connected_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "We choose the normalized term for each connected component\n",
    "- Levenshtein-Median modifies original term (not desirable)\n",
    "- length-based method sometimes yeilds multiple choices\n",
    "\n",
    "After discussion with the dev team, we apply the followng rules to choose normalized terms\n",
    "\n",
    "1. no period at the end\n",
    "2. no hyphen anywhere\n",
    "3. should start with a Uppercased letter\n",
    "4. choose by string length (longest or shorted with repect to entity types)\n",
    "\n",
    "I choose simply the first (or the last) term of each connected component as its normalized term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_normalized(connected_comp, choice='lvst'):\n",
    "    '''\n",
    "    choose one normalized term for each connected component by rule-based system\n",
    "    NOTE: \"longest = False\" will choose the shortest\n",
    "    '''\n",
    "    res = list()\n",
    "    for comp in connected_comp:\n",
    "          \n",
    "        # Rule-1: no period at the end\n",
    "        temp = [name for name in comp if name[-1] != '.']\n",
    "        comp = temp if temp else comp\n",
    "        \n",
    "        # Rule-2.1: no hyphen anywhere\n",
    "        temp = [name for name in comp if '-' not in name]\n",
    "        comp = temp if temp else comp\n",
    "        \n",
    "        # Rule-2.2: no '/' anywhere\n",
    "        temp = [name for name in comp if '/' not in name]\n",
    "        comp = temp if temp else comp\n",
    "        \n",
    "        # Rule-3: start with uppercase\n",
    "        temp = [name for name in comp if name[0].isupper()]\n",
    "        comp = temp if temp else comp\n",
    "        \n",
    "        # Rule-4: no unicode (no '\\u2003')\n",
    "        temp = []\n",
    "        for name in comp:\n",
    "            normal = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore')\n",
    "            val = normal.decode(\"utf-8\")\n",
    "            temp.append(val)\n",
    "            \n",
    "        comp = list(set(temp)) if temp else comp     \n",
    "        \n",
    "        # Rule-5: choose by length or Levenshtein Median\n",
    "        comp.sort(key=len)\n",
    "        if choice == 'long':\n",
    "            res.append(comp[-1])\n",
    "        elif choice == 'short':\n",
    "            res.append(comp[0])\n",
    "        elif choice == 'lvst':\n",
    "            res.append(lvst.median(comp))\n",
    "        else:\n",
    "            print(\"Not a valid choice methond\")\n",
    "            return None\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_terms = choose_normalized(connected_comp, choice='long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalized_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"President Trump's\",\n",
       " \"Bill De Blasio's\",\n",
       " 'Mrs. Jones',\n",
       " 'President Trump',\n",
       " 'Madeleine \"Maddie\" McCann',\n",
       " 'BEAVER DAM',\n",
       " 'Pero la',\n",
       " 'Brian Mahoney',\n",
       " 'Kim Jong Un',\n",
       " 'Nadia Boulanger',\n",
       " 'Gov. DeWine',\n",
       " 'PLANT SALE',\n",
       " 'DEAR ABBY',\n",
       " 'BEETHOVEN',\n",
       " 'President Carter',\n",
       " 'Rihanna',\n",
       " 'LADY GAGA',\n",
       " 'JOE BIDEN',\n",
       " 'Dr. Shah',\n",
       " 'Mr. Cohen',\n",
       " 'Steve McQueen',\n",
       " 'ALMA MAHLER',\n",
       " 'Beekman Street Art Fair',\n",
       " 'Brenda Bethune',\n",
       " 'Adirondack Wine',\n",
       " 'Troy Night Out',\n",
       " \"Drew Brees'\",\n",
       " 'Dr. Martin Luther King',\n",
       " 'Fair Board President',\n",
       " 'Kareem Abdul Jabar',\n",
       " 'Brian Douglass',\n",
       " 'Christiano Ronaldo',\n",
       " 'Robert Cooke',\n",
       " 'Breonne Taylor',\n",
       " 'Valerie A. Arkoosh',\n",
       " 'Don Nelson',\n",
       " 'Antonio Guterres',\n",
       " 'John McCrae',\n",
       " 'Nic Davies',\n",
       " 'Steven Mnuchin',\n",
       " 'Susanna Clark',\n",
       " \"Abraham Lincoln's\",\n",
       " \"Ahmaud Arbery's\",\n",
       " \"Noah Gragson's\",\n",
       " \"Christopher Nolan's\",\n",
       " \"Asa Hutchinson's\",\n",
       " \"Derek Chauvin's\",\n",
       " \"Denver Bazaar's\",\n",
       " \"Lin-Manuel Miranda's\",\n",
       " \"Michelle Lujan Grisham's\"]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_terms[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_norm_dict(components, norms):\n",
    "    raw2normalized = dict()\n",
    "    normalized2raw = defaultdict(list)\n",
    "    for comp, norm in zip(components, norms):\n",
    "        for name in comp:\n",
    "            raw2normalized[name] = norm\n",
    "            normalized2raw[norm].append(name)\n",
    "    \n",
    "    return raw2normalized, normalized2raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2normalized, normalized2raw = make_norm_dict(connected_comp, normalized_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of raw (in-snippet) entiteis normalized: 209\n",
      "# of normalized keys: 102\n"
     ]
    }
   ],
   "source": [
    "print(\"# of raw (in-snippet) entiteis normalized: {}\".format(len(raw2normalized)))\n",
    "print(\"# of normalized keys: {}\".format(len(normalized2raw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of candidate pairs: 2588\n"
     ]
    }
   ],
   "source": [
    "df_persons = get_df_match(persons, 'Person', wiki_match=False, sorting_1st_letters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_person = [4,2,1,1,1]\n",
    "add_match_score(df_persons, weights=weights_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons = cut_off(df_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 8)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_persons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_text</th>\n",
       "      <th>matched</th>\n",
       "      <th>similarity</th>\n",
       "      <th>first_letter_match</th>\n",
       "      <th>dmtph_match</th>\n",
       "      <th>inv_lvst_dist</th>\n",
       "      <th>jw_sim</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beaver Dam</td>\n",
       "      <td>BEAVER DAM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ms. Jones</td>\n",
       "      <td>Mrs. Jones</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brian Mahoney</td>\n",
       "      <td>BRIAN MAHONEY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kim Jong-un</td>\n",
       "      <td>Kim Jong Un</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NADIA BOULANGER</td>\n",
       "      <td>Nadia Boulanger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gov DeWine</td>\n",
       "      <td>Gov. DeWine</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLANT SALE</td>\n",
       "      <td>Plant Sale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DEAR ABBY</td>\n",
       "      <td>Dear Abby</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>President Carter</td>\n",
       "      <td>Mr. Carter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>President Trump's</td>\n",
       "      <td>Mrs. Trump's</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             in_text          matched  similarity  first_letter_match  \\\n",
       "0         Beaver Dam       BEAVER DAM         1.0                True   \n",
       "1          Ms. Jones       Mrs. Jones         1.0                True   \n",
       "2      Brian Mahoney    BRIAN MAHONEY         1.0                True   \n",
       "3        Kim Jong-un      Kim Jong Un         1.0                True   \n",
       "4    NADIA BOULANGER  Nadia Boulanger         1.0                True   \n",
       "5         Gov DeWine      Gov. DeWine         1.0                True   \n",
       "6         PLANT SALE       Plant Sale         1.0                True   \n",
       "7          DEAR ABBY        Dear Abby         1.0                True   \n",
       "8   President Carter       Mr. Carter         1.0                True   \n",
       "9  President Trump's     Mrs. Trump's         1.0                True   \n",
       "\n",
       "   dmtph_match  inv_lvst_dist  jw_sim  match_score  \n",
       "0     0.997527            1.0     1.0     0.999725  \n",
       "1     0.997527            1.0     1.0     0.999725  \n",
       "2     0.997527            1.0     1.0     0.999725  \n",
       "3     0.997527            1.0     1.0     0.999725  \n",
       "4     0.997527            1.0     1.0     0.999725  \n",
       "5     0.997527            1.0     1.0     0.999725  \n",
       "6     0.997527            1.0     1.0     0.999725  \n",
       "7     0.997527            1.0     1.0     0.999725  \n",
       "8     0.997527            1.0     1.0     0.999725  \n",
       "9     0.997527            1.0     1.0     0.999725  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_persons.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_text</th>\n",
       "      <th>matched</th>\n",
       "      <th>similarity</th>\n",
       "      <th>first_letter_match</th>\n",
       "      <th>dmtph_match</th>\n",
       "      <th>inv_lvst_dist</th>\n",
       "      <th>jw_sim</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>William Lesh</td>\n",
       "      <td>William Leslie</td>\n",
       "      <td>0.711813</td>\n",
       "      <td>True</td>\n",
       "      <td>8.315280e-07</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Kenny Porterfield</td>\n",
       "      <td>Kady Porterfield</td>\n",
       "      <td>0.762040</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.791702</td>\n",
       "      <td>0.685924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Tod von George Floyd</td>\n",
       "      <td>von George Floyds Tod</td>\n",
       "      <td>0.819859</td>\n",
       "      <td>True</td>\n",
       "      <td>8.315280e-07</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.682547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Mar&amp;#237;a Blanco</td>\n",
       "      <td>Mar&amp;#237;a Brenes</td>\n",
       "      <td>0.712363</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Garret Smith</td>\n",
       "      <td>Garrett Smithley</td>\n",
       "      <td>0.723815</td>\n",
       "      <td>True</td>\n",
       "      <td>8.315280e-07</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.938889</td>\n",
       "      <td>0.676016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Calais Campbell</td>\n",
       "      <td>Chris Campbell</td>\n",
       "      <td>0.711167</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.834643</td>\n",
       "      <td>0.668085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Ben Crump</td>\n",
       "      <td>Benjamin Crump</td>\n",
       "      <td>0.735444</td>\n",
       "      <td>True</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.665972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Valerie Arkoosh</td>\n",
       "      <td>Valerie A. Arkoosh</td>\n",
       "      <td>0.935304</td>\n",
       "      <td>False</td>\n",
       "      <td>7.310586e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.663150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>James Phillips</td>\n",
       "      <td>J. Phillips</td>\n",
       "      <td>0.710630</td>\n",
       "      <td>True</td>\n",
       "      <td>8.315280e-07</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.779286</td>\n",
       "      <td>0.652423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>William Bryan</td>\n",
       "      <td>Bryan Williams</td>\n",
       "      <td>0.776557</td>\n",
       "      <td>True</td>\n",
       "      <td>8.315280e-07</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.614850</td>\n",
       "      <td>0.644935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 in_text                matched  similarity  \\\n",
       "59          William Lesh         William Leslie    0.711813   \n",
       "60     Kenny Porterfield       Kady Porterfield    0.762040   \n",
       "61  Tod von George Floyd  von George Floyds Tod    0.819859   \n",
       "62     Mar&#237;a Blanco      Mar&#237;a Brenes    0.712363   \n",
       "63          Garret Smith       Garrett Smithley    0.723815   \n",
       "64       Calais Campbell         Chris Campbell    0.711167   \n",
       "65             Ben Crump         Benjamin Crump    0.735444   \n",
       "66       Valerie Arkoosh     Valerie A. Arkoosh    0.935304   \n",
       "67        James Phillips            J. Phillips    0.710630   \n",
       "68         William Bryan         Bryan Williams    0.776557   \n",
       "\n",
       "    first_letter_match   dmtph_match  inv_lvst_dist    jw_sim  match_score  \n",
       "59                True  8.315280e-07       0.333333  1.000000     0.686732  \n",
       "60                True  1.233946e-04       0.333333  0.791702     0.685924  \n",
       "61                True  8.315280e-07       0.111111  0.752381     0.682547  \n",
       "62                True  1.233946e-04       0.250000  1.000000     0.677730  \n",
       "63                True  8.315280e-07       0.250000  0.938889     0.676016  \n",
       "64                True  1.233946e-04       0.333333  0.834643     0.668085  \n",
       "65                True  1.233946e-04       0.200000  0.851852     0.665972  \n",
       "66               False  7.310586e-01       0.500000  0.996078     0.663150  \n",
       "67                True  8.315280e-07       0.250000  0.779286     0.652423  \n",
       "68                True  8.315280e-07       0.083333  0.614850     0.644935  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_persons.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_string=\"2\"\n",
    "f_name = 'person_matching' + ver_string\n",
    "df_persons.to_csv(\"corpus/\" + f_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_connected = connected_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(persons_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_raw2norm = raw2normalized\n",
    "persons_norm2raw = normalized2raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Mr. Trump's\", \"President Trump's\"),\n",
       " (\"President Trump's\", \"President Trump's\"),\n",
       " (\"Mrs. Trump's\", \"President Trump's\"),\n",
       " (\"Bill de Blasio's\", \"Bill De Blasio's\"),\n",
       " ('Bill de Blasio', \"Bill De Blasio's\")]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(persons_raw2norm.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"President Trump's\", [\"Mr. Trump's\", \"President Trump's\", \"Mrs. Trump's\"]),\n",
       " (\"Bill De Blasio's\",\n",
       "  [\"Bill de Blasio's\", 'Bill de Blasio', \"Bill De Blasio's\"]),\n",
       " ('Mrs. Jones', ['Ms. Jones', 'Mr. Jones', 'Mrs. Jones']),\n",
       " ('President Trump', ['Mrs. Trump', 'President Trump', 'Mr. Trump']),\n",
       " ('Madeleine \"Maddie\" McCann',\n",
       "  ['Madeleine McCann', 'van Madeleine McCann', 'Madeleine \"Maddie\" McCann'])]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(persons_norm2raw.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"corpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = 'persons_raw2norm' + ver_string\n",
    "json_dp = json.dumps(persons_raw2norm)\n",
    "with open(data_path + f_name + \".json\",\"w\") as f:\n",
    "    f.write(json_dp)\n",
    "\n",
    "f_name = 'persons_norm2raw' + ver_string\n",
    "json_dp = json.dumps(persons_norm2raw)\n",
    "with open(data_path + f_name + \".json\",\"w\") as f:\n",
    "    f.write(json_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of candidate pairs: 3774\n"
     ]
    }
   ],
   "source": [
    "df_company = get_df_match(company, 'Company', wiki_match=False, sorting_1st_letters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_company = [4,2,1,1,1]\n",
    "add_match_score(df_company, weights=weights_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company = cut_off(df_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_company.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_connected = get_connected_comp(df_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_terms = choose_normalized(company_connected, choice='long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2normalized, normalized2raw = make_norm_dict(company_connected, normalized_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of raw (in-snippet) entiteis normalized: 400\n",
      "# of normalized keys: 194\n"
     ]
    }
   ],
   "source": [
    "print(\"# of raw (in-snippet) entiteis normalized: {}\".format(len(raw2normalized)))\n",
    "print(\"# of normalized keys: {}\".format(len(normalized2raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_string=\"2\"\n",
    "f_name = 'company_matching' + ver_string\n",
    "df_company.to_csv(\"corpus/\" + f_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_raw2norm = raw2normalized\n",
    "company_norm2raw = normalized2raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('World Health  Organization', \"World Health Organization's\"),\n",
       " ('World Health Organization', \"World Health Organization's\"),\n",
       " (\"World Health Organization's\", \"World Health Organization's\"),\n",
       " ('World Health Organisation', \"World Health Organization's\"),\n",
       " ('Cdc', 'CDC')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(company_raw2norm.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"World Health Organization's\",\n",
       "  ['World Health  Organization',\n",
       "   'World Health Organization',\n",
       "   \"World Health Organization's\",\n",
       "   'World Health Organisation']),\n",
       " ('CDC', ['Cdc', 'cdc', 'CDC']),\n",
       " ('M. G', ['M. G', 'M G', 'M.-G']),\n",
       " ('GrubHub', ['Grubhub', 'GRUBHUB', 'GrubHub']),\n",
       " ('Department of Treasury',\n",
       "  ['Department of Defense',\n",
       "   'Department of Treasury',\n",
       "   'Department of Defence'])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(company_norm2raw.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"corpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = 'company_raw2norm' + ver_string\n",
    "json_dp = json.dumps(company_raw2norm)\n",
    "with open(data_path + f_name + \".json\",\"w\") as f:\n",
    "    f.write(json_dp)\n",
    "\n",
    "f_name = 'company_norm2raw' + ver_string\n",
    "json_dp = json.dumps(company_norm2raw)\n",
    "with open(data_path + f_name + \".json\",\"w\") as f:\n",
    "    f.write(json_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of candidate pairs: 4622\n"
     ]
    }
   ],
   "source": [
    "df_location = get_df_match(location, 'Location', wiki_match=False, sorting_1st_letters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_location = [4,2,1,1,1]\n",
    "add_match_score(df_location, weights=weights_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = cut_off(df_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_location.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_connected = get_connected_comp(df_location)\n",
    "connected_comp = location_connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postProcessigUnits(connected_comp):\n",
    "    connected_comp_short_ = sorted([list(comp) for comp in connected_comp if len(comp) == 2], key=lambda x:x[0])\n",
    "    connected_comp_long_ = sorted([list(comp) for comp in connected_comp if len(comp) > 2], key=lambda x:x[0])\n",
    "    connected_comp_all_ = sorted([list(comp) for comp in connected_comp], key=lambda x:x[0])\n",
    "    \n",
    "    connected_comp_short = [(i, comp) for i, comp in enumerate(connected_comp_short_)]\n",
    "    connected_comp_long = [(i, comp) for i, comp in enumerate(connected_comp_long_)]\n",
    "    connected_comp_all = [(i, comp) for i, comp in enumerate(connected_comp_all_)]\n",
    "    \n",
    "    return connected_comp_short, connected_comp_long, connected_comp_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_comp_short, connected_comp_long, connected_comp_all = get_postProcessigUnits(connected_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n",
      "19\n",
      "352\n"
     ]
    }
   ],
   "source": [
    "print(len(connected_comp_short))\n",
    "print(len(connected_comp_long))\n",
    "print(len(connected_comp_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ['12th St.', '12th Street']),\n",
       " (1, ['13th St.', '13th Street']),\n",
       " (2, ['2nd District', '42nd District']),\n",
       " (3, ['4 Franklin Square', 'Franklin Square']),\n",
       " (4, ['4314 39th Ave.', '4314 39th Avenue']),\n",
       " (5, ['75th Avenue', '5th Avenue']),\n",
       " (6, ['ALABAMA', 'Alabama']),\n",
       " (7, ['ALBANY', 'Albany']),\n",
       " (8, ['ASIA', 'Asia']),\n",
       " (9, ['Alaska', 'ALASKA']),\n",
       " (10, ['American Legion Post 1', 'American Legion Post 10']),\n",
       " (11, ['American Legion Post 366', 'American Legion Post 333']),\n",
       " (12, ['American Legion Post 552', 'American Legion Post 502']),\n",
       " (13, ['Antwerp', 'Antwerpen']),\n",
       " (14, ['Arizona', 'ARIZONA']),\n",
       " (15, ['Arlington', 'ARLINGTON']),\n",
       " (16, ['Armenia', 'ARMENIA']),\n",
       " (17, ['Asia-Pacific', 'Asia Pacific']),\n",
       " (18, ['Atlanta', 'ATLANTA']),\n",
       " (19, ['Austin', 'AUSTIN'])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_comp_short[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(connected_comp_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ['12th Ave. North', '12th Avenue North', '12th Ave. N']),\n",
       " (1, ['COLUMBUS', 'Columbus', \"Columbus'\"]),\n",
       " (2, ['Columbus Ohio', 'Columbus, Ohio', 'COLUMBUS, Ohio']),\n",
       " (3, ['Dhaka', 'DHaka', 'DHAKA']),\n",
       " (4, ['Fulton', 'FULTON', 'Fultondale']),\n",
       " (5, ['IRVINE, California', 'Irvine, California', 'IRVINE, Calif.']),\n",
       " (6, [\"Illinois'\", 'ILLINOIS', 'Illinois']),\n",
       " (7, ['JACKSON, Miss.', 'Jackson', 'JACKSON']),\n",
       " (8, ['Los Angeles, Ca.', 'LOS ANGELES, CA', 'Los Angeles, California']),\n",
       " (9, ['Middle East', 'Middle-east', 'Middle-East']),\n",
       " (10, ['NEW YORK', 'New York', 'New-York']),\n",
       " (11, ['Norfolk, Virginia', 'Norfolk, VA', 'NORFOLK, Va.']),\n",
       " (12, ['RICHMOND, Va', 'RICHMOND, VA', 'Richmond, VA']),\n",
       " (13, ['Saratoga county', 'SARATOGA COUNTY', 'Saratoga County']),\n",
       " (14, ['St. Louis', 'ST. LOUIS', 'St Louis']),\n",
       " (15, [\"Texas'\", 'Texas', 'TEXAS']),\n",
       " (16,\n",
       "  ['WASHINGTON D.C.',\n",
       "   'Washington D.C.',\n",
       "   'Washington, D.C.',\n",
       "   'WASHINGTON, D.C.']),\n",
       " (17, ['Washington DC', 'WASHINGTON DC', 'WASHINGTON, DC', 'Washington, DC']),\n",
       " (18,\n",
       "  ['the United States  of  America',\n",
       "   'The United States of America',\n",
       "   'the United States of America'])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_comp_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual insepction to excude, connect & add\n",
    "index2exclude = [4,7]\n",
    "index2connect = [(16,17)]\n",
    "comp2add = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index2exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking(connected_comp_any, index2connect=[] ,index2exclude=[]):\n",
    "    chunks = list()\n",
    "    if index2connect:\n",
    "        for tp in index2connect: \n",
    "            chunk = list()\n",
    "            for idx in tp:\n",
    "                chunk.extend(list(connected_comp_any[idx][1]))\n",
    "                index2exclude.append(idx)\n",
    "\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "    return chunks, index2exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comp_final(connected_comp, connected_comp_short, is_all=True\n",
    "                   , *, index2connect=[], index2exclude=[], comp2add=[]):\n",
    "    chunks, index2exclude = chunking(connected_comp, index2connect=index2connect, index2exclude=index2exclude)\n",
    "    \n",
    "    res = [list(a[1]) for i, a in enumerate(connected_comp) if i not in index2exclude]\n",
    "    res.extend(chunks)\n",
    "    res.extend(comp2add)\n",
    "    \n",
    "    if not is_all:\n",
    "        res += [list(a[1]) for a in connected_comp_short]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_comp_final = get_comp_final(connected_comp_long, connected_comp_short, is_all=False\n",
    "                                     , index2connect=index2connect\n",
    "                                     , index2exclude=index2exclude\n",
    "                                     , comp2add=comp2add\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "349\n"
     ]
    }
   ],
   "source": [
    "print(len(connected_comp))\n",
    "print(len(connected_comp_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_connected = connected_comp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_terms = choose_normalized(location_connected, choice='long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2normalized, normalized2raw = make_norm_dict(location_connected, normalized_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of raw (in-snippet) entiteis normalized: 719\n",
      "# of normalized keys: 349\n"
     ]
    }
   ],
   "source": [
    "print(\"# of raw (in-snippet) entiteis normalized: {}\".format(len(raw2normalized)))\n",
    "print(\"# of normalized keys: {}\".format(len(normalized2raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_string=\"2\"\n",
    "f_name = 'location_matching' + ver_string\n",
    "df_location.to_csv(\"corpus/\" + f_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_raw2norm = raw2normalized\n",
    "location_norm2raw = normalized2raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('12th Ave. North', '12th Avenue North'),\n",
       " ('12th Avenue North', '12th Avenue North'),\n",
       " ('12th Ave. N', '12th Avenue North'),\n",
       " ('COLUMBUS', \"Columbus'\"),\n",
       " ('Columbus', \"Columbus'\")]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(location_raw2norm.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('12th Avenue North',\n",
       "  ['12th Ave. North', '12th Avenue North', '12th Ave. N']),\n",
       " (\"Columbus'\", ['COLUMBUS', 'Columbus', \"Columbus'\"]),\n",
       " ('COLUMBUS, Ohio', ['Columbus Ohio', 'Columbus, Ohio', 'COLUMBUS, Ohio']),\n",
       " ('DHAKA', ['Dhaka', 'DHaka', 'DHAKA']),\n",
       " ('Irvine, California',\n",
       "  ['IRVINE, California', 'Irvine, California', 'IRVINE, Calif.'])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(location_norm2raw.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"corpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = 'location_raw2norm' + ver_string\n",
    "json_dp = json.dumps(location_raw2norm)\n",
    "with open(data_path + f_name + \".json\",\"w\") as f:\n",
    "    f.write(json_dp)\n",
    "\n",
    "f_name = 'location_norm2raw' + ver_string\n",
    "json_dp = json.dumps(location_norm2raw)\n",
    "with open(data_path + f_name + \".json\",\"w\") as f:\n",
    "    f.write(json_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery",
   "language": "python",
   "name": "discovery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
